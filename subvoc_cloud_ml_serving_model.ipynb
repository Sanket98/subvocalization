{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.lib.io import file_io\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from random import shuffle\n",
    "from scipy import signal\n",
    "from scipy.io import wavfile\n",
    "from scipy import interpolate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.logging.set_verbosity(tf.logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TFR_TRAIN = 'train.tfrecord'\n",
    "TFR_VALID = 'valid.tfrecord'\n",
    "TFR_TEST = 'test.tfrecord'\n",
    "BUCKET = 'gs://robolab/'\n",
    "\n",
    "NUM_CLASSES = 2\n",
    "\n",
    "IMG_HEIGHT = 80 # four concatenated cropped specs = 4 * 20\n",
    "IMG_WIDTH = 71"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-Parsers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bytes_feature(value):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parser(serialized_example):\n",
    "\n",
    "    features = tf.parse_single_example(\n",
    "        serialized_example,\n",
    "        features={\n",
    "            'image_raw': tf.FixedLenFeature([], tf.string),\n",
    "            'label': tf.FixedLenFeature([], tf.string)})\n",
    "\n",
    "    image = tf.decode_raw(features['image_raw'], tf.float32)\n",
    "    image.set_shape([IMG_HEIGHT * IMG_WIDTH])\n",
    "\n",
    "    label = tf.decode_raw(features['label'], tf.int32)\n",
    "    label.set_shape([1])\n",
    "\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_parser(serialized_example):\n",
    "\n",
    "    features = tf.parse_single_example(\n",
    "        serialized_example,\n",
    "        features={'image_raw': tf.FixedLenFeature([], tf.string)})\n",
    "\n",
    "    image = tf.decode_raw(features['image_raw'], tf.float32)\n",
    "    image.set_shape([IMG_HEIGHT * IMG_WIDTH])\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_input_fn():\n",
    "\n",
    "    # get dataset from tf_record\n",
    "    dataset = tf.data.TFRecordDataset(BUCKET + TFR_TRAIN)\n",
    "\n",
    "    # map parser over dataset samples\n",
    "    dataset = dataset.map(parser)\n",
    "    dataset = dataset.shuffle(1000)\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    dataset = dataset.repeat(1)\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "\n",
    "    features, labels = iterator.get_next()\n",
    "\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_input_fn():\n",
    "\n",
    "    # get dataset from tf_record\n",
    "    dataset = tf.data.TFRecordDataset(BUCKET + TFR_TRAIN)\n",
    "\n",
    "    # map parser over dataset samples\n",
    "    dataset = dataset.map(parser)\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    dataset = dataset.repeat(1)\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "\n",
    "    features, labels = iterator.get_next()\n",
    "\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_input_fn():\n",
    "\n",
    "    # get dataset from tf_record\n",
    "    dataset = tf.data.TFRecordDataset(BUCKET + TFR_VALID)\n",
    "\n",
    "    # map parser over dataset samples\n",
    "    dataset = dataset.map(parser)\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    dataset = dataset.repeat(1)\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "\n",
    "    features, labels = iterator.get_next()\n",
    "\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_input_fn():\n",
    "\n",
    "    # get dataset from tf_record\n",
    "    dataset = tf.data.TFRecordDataset(BUCKET + TFR_TEST)\n",
    "\n",
    "    # map parser over dataset samples\n",
    "    dataset = dataset.map(test_parser)\n",
    "    dataset = dataset.batch(1)\n",
    "    dataset = dataset.repeat(1)\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "\n",
    "    features = iterator.get_next()\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model_fn(features, labels, mode):\n",
    "    \n",
    "    input_layer = tf.reshape(features, [-1, IMG_HEIGHT, IMG_WIDTH], name='input_bytes')\n",
    "    input_layer = tf.expand_dims(input_layer, axis=3)\n",
    "\n",
    "    conv_layer_1 = tf.layers.conv2d(\n",
    "        inputs=input_layer,\n",
    "        filters=8,\n",
    "        kernel_size=[2, 2],\n",
    "        padding='same',\n",
    "        activation=tf.nn.relu)\n",
    "\n",
    "    pool_layer_1 = tf.layers.max_pooling2d(\n",
    "        inputs=conv_layer_1,\n",
    "        pool_size=[2, 2],\n",
    "        strides=2,\n",
    "        padding='same')\n",
    "\n",
    "    conv_layer_2 = tf.layers.conv2d(\n",
    "        inputs=pool_layer_1,\n",
    "        filters=32,\n",
    "        kernel_size=[2, 2],\n",
    "        padding='same',\n",
    "        activation=tf.nn.relu)\n",
    "\n",
    "    pool_layer_2 = tf.layers.max_pooling2d(\n",
    "        inputs=conv_layer_2,\n",
    "        pool_size=[2, 2],\n",
    "        strides=2,\n",
    "        padding='same')\n",
    "\n",
    "    reshape_layer = tf.layers.flatten(pool_layer_2)\n",
    "\n",
    "    dense_layer = tf.layers.dense(\n",
    "        inputs=reshape_layer,\n",
    "        units=256,\n",
    "        activation=tf.nn.relu)\n",
    "    \n",
    "    is_train = False\n",
    "\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        is_train = True\n",
    "\n",
    "    dropout_layer = tf.layers.dropout(\n",
    "        inputs=dense_layer,\n",
    "        rate=0.2,\n",
    "        training=is_train)\n",
    "\n",
    "    logits_layer = tf.layers.dense(\n",
    "        inputs=dropout_layer,\n",
    "        units=NUM_CLASSES)\n",
    "\n",
    "    predictions = {\n",
    "        'classes':tf.argmax(logits_layer, axis=1),\n",
    "        'probabilities':tf.nn.softmax(logits_layer, axis=1)}\n",
    "\n",
    "    serving_output = tf.estimator.export.ClassificationOutput(scores=predictions['probabilities'])\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode,\n",
    "                                          predictions=predictions,\n",
    "                                          export_outputs={'x':serving_output})\n",
    "\n",
    "    loss = tf.losses.sparse_softmax_cross_entropy(\n",
    "        labels=labels,\n",
    "        logits=logits_layer)\n",
    "\n",
    "    accuracy = tf.metrics.accuracy(\n",
    "        labels=labels,\n",
    "        predictions=tf.argmax(logits_layer, axis=1),\n",
    "        name='accu_op')\n",
    "\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        train_optimizer = tf.train.AdamOptimizer(learning_rate=LR).minimize(\n",
    "            loss=loss,\n",
    "            global_step=tf.train.get_global_step())\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_optimizer)\n",
    "\n",
    "    # mode = EVAL\n",
    "    eval_metric_ops = {'accuracy':accuracy}\n",
    "\n",
    "    return tf.estimator.EstimatorSpec(mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTDIR = BUCKET + 'output'\n",
    "\n",
    "cnn_classifier = tf.estimator.Estimator(model_fn=cnn_model_fn, model_dir=OUTDIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create serving_input_receiver_fn for serving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serving_input_receiver_fn():\n",
    "    \n",
    "    serialized_example = tf.placeholder(dtype=tf.string,\n",
    "                                       shape=[None],\n",
    "                                       name='raw_bytes')\n",
    "    \n",
    "    receiver_tensors = {'examples': serialized_example}\n",
    "    \n",
    "    feats = tf.parse_example(\n",
    "        serialized_example,\n",
    "        {'image_raw': tf.FixedLenFeature([], tf.string)})\n",
    "    \n",
    "    fn = lambda x: tf.decode_raw(x, tf.float32)\n",
    "    \n",
    "    feats = tf.map_fn(fn, feats['image_raw'], dtype=tf.float32, name='parser')\n",
    "    feats.set_shape([None, IMG_HEIGHT * IMG_WIDTH])\n",
    "    \n",
    "    return tf.estimator.export.TensorServingInputReceiver(feats, receiver_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"parser/TensorArrayStack/TensorArrayGatherV3:0\", shape=(?, 5680), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "b'gs://robolab/saved_model/1543691652'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_classifier.export_saved_model('gs://robolab/saved_model', serving_input_receiver_fn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
